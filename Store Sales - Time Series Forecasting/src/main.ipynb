{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:21:32.375147Z",
     "start_time": "2026-01-02T19:21:32.363556Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "69dd3879274e19f1",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Firstly, we need to load the data.",
   "id": "cdd7d46a376aede1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:21:33.962849Z",
     "start_time": "2026-01-02T19:21:32.381466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "oil = pd.read_csv('../data/oil.csv')\n",
    "stores = pd.read_csv('../data/stores.csv')\n",
    "transaction = pd.read_csv('../data/transactions.csv')\n",
    "holidays = pd.read_csv('../data/holidays_events.csv')"
   ],
   "id": "76cb50627f17e7e1",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then we need to view the shape and the columns contained in each file / dataframe so we can better recognise how to merge the data, and what we can actually use.",
   "id": "87692e8226d5d677"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:21:34.033783Z",
     "start_time": "2026-01-02T19:21:34.011130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Train data:\\n {train_data.head()}\")\n",
    "print(f\"Test data:\\n {test_data.head()}\")\n",
    "print(f\"Oil data:\\n {oil.head()}\")\n",
    "print(f\"Store data:\\n {stores.head()}\")\n",
    "print(f\"Transaction data:\\n {transaction.head()}\")\n",
    "print(f\"Holidays data:\\n {holidays.head()}\")"
   ],
   "id": "e5305d8d1ac13dc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "    id        date  store_nbr      family  sales  onpromotion\n",
      "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
      "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
      "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
      "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
      "4   4  2013-01-01          1       BOOKS    0.0            0\n",
      "Test data:\n",
      "         id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0\n",
      "Oil data:\n",
      "          date  dcoilwtico\n",
      "0  2013-01-01         NaN\n",
      "1  2013-01-02       93.14\n",
      "2  2013-01-03       92.97\n",
      "3  2013-01-04       93.12\n",
      "4  2013-01-07       93.20\n",
      "Store data:\n",
      "    store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4\n",
      "Transaction data:\n",
      "          date  store_nbr  transactions\n",
      "0  2013-01-01         25           770\n",
      "1  2013-01-02          1          2111\n",
      "2  2013-01-02          2          2358\n",
      "3  2013-01-02          3          3487\n",
      "4  2013-01-02          4          1922\n",
      "Holidays data:\n",
      "          date     type    locale locale_name                    description  \\\n",
      "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
      "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "So, the distinctive data we can use, so that we can get the best possible prediction results, is if we use as an index the store and the date where it is possible. We now need to merge the date and make sure we have a consistent time frame, so we want our input data to have a 1 day difference, between 2 data rows, we have to make sure our data is ordered by date.",
   "id": "43d20448b8e18ff4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:21:34.877637Z",
     "start_time": "2026-01-02T19:21:34.039929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "transaction['date'] = pd.to_datetime(transaction['date'])\n",
    "holidays['date'] = pd.to_datetime(holidays['date'])\n",
    "\n",
    "train_data = train_data.merge(\n",
    "    oil, how='left', on='date'\n",
    ")\n",
    "\n",
    "\n",
    "train_data = train_data.merge(\n",
    "    stores,\n",
    "    how='left',\n",
    "    on=['store_nbr']\n",
    ")\n",
    "\n",
    "test_data = test_data.merge(\n",
    "    oil, how='left', on='date'\n",
    ")\n",
    "\n",
    "test_data = test_data.merge(\n",
    "    stores,\n",
    "    how='left',\n",
    "    on=['store_nbr']\n",
    ")"
   ],
   "id": "6be7d29114089aa8",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We did not merge all the available data yet. If we pay attention to the dataframes, we notice that the transaction data have no available data about the dates we want to predict the value of, if we just try to merge those tables, in the test data, we will just a get a column filled with nan / null values, the only thing this can do is throw off our predictions. The data we get from this dataset though is highly valuable, so we cannot just not use it. What we can actually do is work with lags and window frames. The logic for that is to actually match future dates with past values. For the lag data, we can agree on a consistent lag time frame, and just use the say average of the last 7 days as the prediction for the current date.",
   "id": "b5c7beef47efb64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T19:21:42.116738Z",
     "start_time": "2026-01-02T19:21:34.916045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = train_data.merge(transaction, how='left', on=['date', 'store_nbr'])\n",
    "test_data = test_data.merge(transaction, how='left', on=['date', 'store_nbr'])\n",
    "\n",
    "train_data = train_data.sort_values(['date'])\n",
    "test_data  = test_data.sort_values(['date'])\n",
    "\n",
    "\n",
    "full = pd.concat([train_data, test_data])\n",
    "full = full.sort_values(['date'])\n",
    "\n",
    "full['transaction_lag_7'] = full.groupby('store_nbr')['transactions'].shift(7)\n",
    "full['transaction_roll_mean_7'] = (\n",
    "    full.groupby('store_nbr')['transactions']\n",
    "    .transform(lambda x: x.shift(1).rolling(7, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "train_data = full.loc[train_data.index]\n",
    "test_data  = full.loc[test_data.index]\n",
    "\n",
    "test_data.drop(columns=['transactions'], inplace=True)\n",
    "train_data.drop(columns=['transactions'], inplace=True)\n",
    "\n",
    "print(train_data['transaction_lag_7'].isna().count())\n",
    "print(train_data['transaction_roll_mean_7'].isna().count())\n",
    "print(train_data.size)\n",
    "\n",
    "print(test_data['transaction_lag_7'].isna().count())\n",
    "print(test_data['transaction_roll_mean_7'].isna().count())\n",
    "print(test_data.size)\n",
    "\n",
    "print(f\"New train data:\\n {train_data.head()}\")\n",
    "print(f\"New test data:\\n {test_data.head()}\")"
   ],
   "id": "3d093bae8d179bd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3029400\n",
      "3029400\n",
      "39382200\n",
      "57024\n",
      "57024\n",
      "741312\n",
      "New train data:\n",
      "            id       date  store_nbr        family  sales  onpromotion  \\\n",
      "0           0 2013-01-01          1    AUTOMOTIVE    0.0            0   \n",
      "0     3000888 2017-08-16          1    AUTOMOTIVE    NaN            0   \n",
      "1194     1194 2013-01-01         42   CELEBRATION    0.0            0   \n",
      "1194  3002082 2017-08-16         42   CELEBRATION    NaN            0   \n",
      "1193     1193 2013-01-01         42  BREAD/BAKERY    0.0            0   \n",
      "\n",
      "      dcoilwtico    city      state type  cluster  transaction_lag_7  \\\n",
      "0            NaN   Quito  Pichincha    D       13                NaN   \n",
      "0           46.8   Quito  Pichincha    D       13                NaN   \n",
      "1194         NaN  Cuenca      Azuay    D        2                NaN   \n",
      "1194        46.8  Cuenca      Azuay    D        2                NaN   \n",
      "1193         NaN  Cuenca      Azuay    D        2                NaN   \n",
      "\n",
      "      transaction_roll_mean_7  \n",
      "0                         NaN  \n",
      "0                         NaN  \n",
      "1194                      NaN  \n",
      "1194                      NaN  \n",
      "1193                      NaN  \n",
      "New test data:\n",
      "            id       date  store_nbr        family  sales  onpromotion  \\\n",
      "0           0 2013-01-01          1    AUTOMOTIVE    0.0            0   \n",
      "0     3000888 2017-08-16          1    AUTOMOTIVE    NaN            0   \n",
      "1194     1194 2013-01-01         42   CELEBRATION    0.0            0   \n",
      "1194  3002082 2017-08-16         42   CELEBRATION    NaN            0   \n",
      "1193     1193 2013-01-01         42  BREAD/BAKERY    0.0            0   \n",
      "\n",
      "      dcoilwtico    city      state type  cluster  transaction_lag_7  \\\n",
      "0            NaN   Quito  Pichincha    D       13                NaN   \n",
      "0           46.8   Quito  Pichincha    D       13                NaN   \n",
      "1194         NaN  Cuenca      Azuay    D        2                NaN   \n",
      "1194        46.8  Cuenca      Azuay    D        2                NaN   \n",
      "1193         NaN  Cuenca      Azuay    D        2                NaN   \n",
      "\n",
      "      transaction_roll_mean_7  \n",
      "0                         NaN  \n",
      "0                         NaN  \n",
      "1194                      NaN  \n",
      "1194                      NaN  \n",
      "1193                      NaN  \n"
     ]
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
